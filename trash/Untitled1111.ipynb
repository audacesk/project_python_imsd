{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import lxml.html as lh\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_combinator_scraper():\n",
    "    \n",
    "    # Listing des URLs à scraper\n",
    "    s_05 = 'https://www.ycdb.co/batch/s05'\n",
    "    w_06 = 'https://www.ycdb.co/batch/w06'\n",
    "    s_06 = 'https://www.ycdb.co/batch/s06'\n",
    "\n",
    "    \n",
    "    # Liste python regroupant les URLs mentionnées. Cette liste va permettre d'itérer la fonction sur chaque lien recherché\n",
    "    urls = [s_05]\n",
    "    \n",
    "    # Début de la bouble itérative\n",
    "    for i in tqdm(urls):\n",
    "        # Ouvrir une session firefox\n",
    "        driver = webdriver.Firefox()\n",
    "        driver.get(i)\n",
    "        driver.implicitly_wait(100)\n",
    "        \n",
    "        # Suppression des cookies\n",
    "        driver.delete_all_cookies()\n",
    "        \n",
    "        # Chercher l'emplacement de la liste du nombre d'affichage d'élément puis clicker dessus\n",
    "        driver.find_element_by_name('table_length').click()\n",
    "        \n",
    "        # Cliquer sur \"all\" afin d'afficher tous les éléments sur la même page\n",
    "        driver.find_element_by_xpath('/html/body/div[1]/div[1]/div[2]/div/div[1]/div[1]/div/label/select/option[6]').click()\n",
    "        \n",
    "        # Obtenir la page source de la page afin de scrapper par la suite via BeautifulSoup\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        '''# Appeler l'URL à scraper\n",
    "        url = based_url + i\n",
    "        response = get(url)'''\n",
    "\n",
    "        # Lancer une session BeautifulSoup, localiser puis stocker l'adresse de localisaiton du contenu de la page\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')    \n",
    "        my_table = soup.find('table','table')\n",
    "\n",
    "        # Initialisation des listes que nous rempliront par la suite\n",
    "        noms = []\n",
    "        batch = []\n",
    "        #categories = []\n",
    "        descriptions = []\n",
    "        variable = []\n",
    "\n",
    "        # Répertorier les emplacements des éléments recherchés\n",
    "        names = my_table.find_all('a')\n",
    "        batches = my_table.find_all('td', 'd-none d-md-table-cell')[0::2]\n",
    "        #category = my_table.find_all('td', '')\n",
    "        description = my_table.find_all('td', 'd-none d-md-table-cell ellipsis')\n",
    "        text_right = my_table.find_all('td', 'text-right d-none d-md-table-cell')\n",
    "\n",
    "        # Noms\n",
    "        for y in tqdm(names):\n",
    "            if names is not None:\n",
    "                nam = str(y.text.strip())\n",
    "                noms.append(nam)\n",
    "            else:\n",
    "                nam == 'null'\n",
    "                noms.append(nam)\n",
    "                \n",
    "        # Batch\n",
    "        for y in tqdm(batches):\n",
    "            if batches is not None:\n",
    "                bat = str(y.text)\n",
    "                batch.append(bat)\n",
    "            else:\n",
    "                batch = 'null'\n",
    "                batch.append(bat)\n",
    "                \n",
    "        '''# Catégories\n",
    "        for y in category:\n",
    "            cat = y.text\n",
    "            categories.append(cat)'''\n",
    "\n",
    "        # Descriptions\n",
    "        for y in tqdm(description):\n",
    "            if description is not None:\n",
    "                des = str(y.text)\n",
    "                descriptions.append(des)\n",
    "            else:\n",
    "                des = 'null'\n",
    "                descriptions.append(des)\n",
    "\n",
    "        # Élément différentiateur\n",
    "        for y in tqdm(text_right):\n",
    "            if text_right is not None:\n",
    "                lev = str(y.text)\n",
    "                variable.append(lev)\n",
    "            else:\n",
    "                lev = 'null'\n",
    "                variable.append(lev)\n",
    "        \n",
    "        ''' Incrémentation de la variable 'rank'\n",
    "        rank += 1'''\n",
    "        \n",
    "        # Regroupement des listes dans un np.array\n",
    "        datas = np.column_stack((noms,batch,descriptions,variable))\n",
    "        #datas = np.concatenate((noms,batch,categories,descriptions,variable[:,None]),axis=1)\n",
    "        \n",
    "        # Transformation du np.array en un pd.DataFrame\n",
    "        df = pd.DataFrame(datas, columns=['noms', 'batch', 'descriptions', 'variable'])\n",
    "        \n",
    "        # Fermer la page\n",
    "        driver.close()\n",
    "        \n",
    "        '''# Export vers un fichier excel de nom 'ranking' + numéro du classement + nom du classement\n",
    "        df.to_excel(excel_writer= 'ranking_' + str(rank) + '_' + i + '.xlsx')'''\n",
    "\n",
    "        '''ATTENTION: les images seront à remettre dans le rendu final'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 5495.16it/s]\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 2999.14it/s]\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 5495.16it/s]\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 5501.71it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d4c67e554e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_combinator_scraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-8dfa72bd2398>\u001b[0m in \u001b[0;36my_combinator_scraper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Regroupement des listes dans un np.array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mdatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;31m#datas = np.concatenate((noms,batch,categories,descriptions,variable[:,None]),axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "y_combinator_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
